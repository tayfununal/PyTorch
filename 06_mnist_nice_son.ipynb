{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxoWTb3wZfmhw5iVQyPW83",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/PyTorch/blob/main/06_mnist_nice_son.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "87RALZ-3O9AN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import make_moons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        super(Data, self).__init__()\n",
        "\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.dataset.data[idx]\n",
        "        y = self.dataset.targets[idx]\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "y_iZwiHXO_bt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NICE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layer, num_flows=2):\n",
        "        super(NICE, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.num_flows = num_flows\n",
        "\n",
        "        self.net = lambda : nn.Sequential(\n",
        "                                 nn.Linear(self.input_dim//2, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.input_dim//2)) # input dimension must be equal to output dimension\n",
        "\n",
        "        self.m = nn.ModuleList([self.net() for _ in range(self.num_flows)])\n",
        "\n",
        "        self.s = nn.Parameter(torch.rand(1, input_dim), requires_grad=True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x[0].to(torch.float32)\n",
        "        x = x.view(len(x), -1,) / 255\n",
        "        return self.f(x)\n",
        "\n",
        "    def coupling_layer(self, x, m, flow, forward=True):\n",
        "        x = x.clone()\n",
        "\n",
        "        x_a = x[:, ::2] if flow%2==0 else x[:, 1::2]\n",
        "        x_b = x[:, 1::2] if flow%2==0 else x[:, ::2]\n",
        "\n",
        "        if forward:\n",
        "            y_b = x_b - m(x_a)\n",
        "        else:\n",
        "            y_b = x_b + m(x_a)\n",
        "\n",
        "        #z = torch.concat((x_a, y_b), axis=1) if flow%2==0 else torch.concat((y_b, x_a), axis=1)\n",
        "        z = torch.empty(x.shape)\n",
        "        z[:, ::2] = x_a if flow%2==0 else y_b\n",
        "        z[:, 1::2] = y_b if flow%2==0 else x_a\n",
        "        return z\n",
        "\n",
        "\n",
        "    def f(self, x):\n",
        "        z = x\n",
        "\n",
        "        for flow, model in enumerate(self.m, start=0):\n",
        "            z = self.coupling_layer(z, model, flow, forward=True)\n",
        "\n",
        "        z = z / torch.exp(self.s)\n",
        "        log_det_j = torch.sum(torch.abs(self.s))\n",
        "\n",
        "        return z, log_det_j\n",
        "\n",
        "    def f_inv(self, z):\n",
        "        x = z * torch.exp(self.s)\n",
        "\n",
        "        for flow, model in reversed(list(enumerate(self.m, start=0))):\n",
        "            x = self.coupling_layer(x, model, flow,forward=False)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def criterion(self, z, prior, log_det_j, reduction = \"sum\"):\n",
        "\n",
        "        if reduction == \"sum\":\n",
        "            loss = - (prior.log_prob(z) + log_det_j).sum()\n",
        "        else:\n",
        "\n",
        "            loss = - (prior.log_prob(z) - log_det_j).mean()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "dNv7fminO_d7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image = torchvision.datasets.MNIST(root='dataset', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_image = torchvision.datasets.MNIST(root='dataset', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "\n",
        "train_data = Data(train_image)\n",
        "test_data = Data(test_image)"
      ],
      "metadata": {
        "id": "61Bk8bccO_gl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_train, category_train = train_data[0]\n",
        "image_test, category_test = test_data[0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(image_train.reshape((28,28)), cmap='gray')\n",
        "plt.title(f'train\\ntarget : {category_train}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(image_test.reshape((28,28)), cmap='gray')\n",
        "plt.title(f'test\\ntarget : {category_test}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mn2HDNucO_i_",
        "outputId": "95124340-6dec-430f-c899-a26fca8e9163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dim = 28*28\n",
        "\"\"\"\n",
        "prior = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros((data_dim)),\n",
        "                                                    scale_tril=torch.diag(torch.ones((data_dim))))\n",
        "\"\"\"\n",
        "prior = torch.distributions.normal.Normal(loc=torch.zeros((data_dim)),\n",
        "                                                    scale=torch.ones((data_dim)))\n",
        "\n",
        "model = NICE(input_dim=data_dim, hidden_layer=512, num_flows=20)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=5000, shuffle=True)\n"
      ],
      "metadata": {
        "id": "rQs7Q0x8O_lW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)   # weight_decay=0.9\n",
        "\n",
        "COST = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = []\n",
        "\n",
        "    for x in train_loader:\n",
        "\n",
        "        z, log_det_j = model.forward(x)\n",
        "        loss = model.criterion(z, prior, log_det_j, reduction=\"avg\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "    COST.append(np.mean(total_loss))\n",
        "\n",
        "    if epoch==0:\n",
        "        print(\"Epoch : \", epoch+1, \"  -----------> Loss : \", np.mean(total_loss))\n",
        "    elif (epoch+1)%1 == 0:\n",
        "        print(\"Epoch : \", epoch+1, \"  -----------> Loss : \", np.mean(total_loss))"
      ],
      "metadata": {
        "id": "wwMpBqaBO_np",
        "outputId": "7ff3ed6c-7069-4b5a-bc8d-4ee581d02988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  1   -----------> Loss :  371.0894724527995\n",
            "Epoch :  2   -----------> Loss :  361.80809020996094\n",
            "Epoch :  3   -----------> Loss :  352.61021677652997\n",
            "Epoch :  4   -----------> Loss :  343.54291280110675\n",
            "Epoch :  5   -----------> Loss :  334.6163965861003\n",
            "Epoch :  6   -----------> Loss :  325.79803975423175\n",
            "Epoch :  7   -----------> Loss :  317.0936787923177\n",
            "Epoch :  8   -----------> Loss :  308.4929707845052\n",
            "Epoch :  9   -----------> Loss :  300.0028559366862\n",
            "Epoch :  10   -----------> Loss :  291.6459147135417\n",
            "Epoch :  11   -----------> Loss :  283.43135833740234\n",
            "Epoch :  12   -----------> Loss :  275.3154474894206\n",
            "Epoch :  13   -----------> Loss :  267.3159917195638\n",
            "Epoch :  14   -----------> Loss :  259.423158009847\n",
            "Epoch :  15   -----------> Loss :  251.65860748291016\n",
            "Epoch :  16   -----------> Loss :  244.01352310180664\n",
            "Epoch :  17   -----------> Loss :  236.48653030395508\n",
            "Epoch :  18   -----------> Loss :  229.1625188191732\n",
            "Epoch :  19   -----------> Loss :  221.97879918416342\n",
            "Epoch :  20   -----------> Loss :  214.9316495259603\n",
            "Epoch :  21   -----------> Loss :  207.9945411682129\n",
            "Epoch :  22   -----------> Loss :  201.2458813985189\n",
            "Epoch :  23   -----------> Loss :  194.6190299987793\n",
            "Epoch :  24   -----------> Loss :  188.08028666178384\n",
            "Epoch :  25   -----------> Loss :  181.62666956583658\n",
            "Epoch :  26   -----------> Loss :  175.2734031677246\n",
            "Epoch :  27   -----------> Loss :  169.05730438232422\n",
            "Epoch :  28   -----------> Loss :  163.0263760884603\n",
            "Epoch :  29   -----------> Loss :  157.18044789632162\n",
            "Epoch :  30   -----------> Loss :  151.53206380208334\n",
            "Epoch :  31   -----------> Loss :  146.02314249674478\n",
            "Epoch :  32   -----------> Loss :  140.64113108317056\n",
            "Epoch :  33   -----------> Loss :  135.341433207194\n",
            "Epoch :  34   -----------> Loss :  130.15785598754883\n",
            "Epoch :  35   -----------> Loss :  125.0884297688802\n",
            "Epoch :  36   -----------> Loss :  120.09814008076985\n",
            "Epoch :  37   -----------> Loss :  115.22021929423015\n",
            "Epoch :  38   -----------> Loss :  110.51403109232585\n",
            "Epoch :  39   -----------> Loss :  105.95516014099121\n",
            "Epoch :  40   -----------> Loss :  101.52194277445476\n",
            "Epoch :  41   -----------> Loss :  97.16805203755696\n",
            "Epoch :  42   -----------> Loss :  92.92101923624675\n",
            "Epoch :  43   -----------> Loss :  88.74277178446452\n",
            "Epoch :  44   -----------> Loss :  84.65640449523926\n",
            "Epoch :  45   -----------> Loss :  80.65268135070801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(COST)"
      ],
      "metadata": {
        "id": "3lgGpF_wybkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = prior.sample((50,))\n",
        "test"
      ],
      "metadata": {
        "id": "qJy70H-_O_pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sonuc = model.f_inv(test)\n",
        "sonuc"
      ],
      "metadata": {
        "id": "rjNtmsr9O_sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = prior.sample((50,))\n",
        "sonuc = model.f_inv(test)\n",
        "\n",
        "fig, axs = plt.subplots(5, 10, sharex=True, sharey=True, figsize=(18, 8))\n",
        "\n",
        "for i in range(0,10):\n",
        "\n",
        "    axs[0, i].imshow(torch.nn.ReLU()(sonuc[i]).detach().numpy().reshape((28,28)), cmap='gray')\n",
        "    axs[1, i].imshow(torch.nn.ReLU()(sonuc[10+i]).detach().numpy().reshape((28,28)), cmap='gray')\n",
        "    axs[2, i].imshow(torch.nn.ReLU()(sonuc[20+i]).detach().numpy().reshape((28,28)), cmap='gray')\n",
        "    axs[3, i].imshow(torch.nn.ReLU()(sonuc[30+i]).detach().numpy().reshape((28,28)), cmap='gray')\n",
        "    axs[4, i].imshow(torch.nn.ReLU()(sonuc[40+i]).detach().numpy().reshape((28,28)), cmap='gray')\n",
        "    axs[0, i].axis('off')\n",
        "    axs[1, i].axis('off')\n",
        "    axs[2, i].axis('off')\n",
        "    axs[3, i].axis('off')\n",
        "    axs[4, i].axis('off')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EJXVv9wyPMXm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}