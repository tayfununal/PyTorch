{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/PyTorch/blob/main/05_mnist_nice_son.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "87RALZ-3O9AN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import make_moons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        super(Data, self).__init__()\n",
        "\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.dataset.data[idx]\n",
        "        y = self.dataset.targets[idx]\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "y_iZwiHXO_bt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NICE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layer, num_flows=2):\n",
        "        super(NICE, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.num_flows = num_flows\n",
        "\n",
        "        self.net = lambda : nn.Sequential(\n",
        "                                 nn.Linear(self.input_dim//2, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.hidden_layer), nn.ReLU(),\n",
        "                                 nn.Linear(self.hidden_layer, self.input_dim//2)) # input dimension must be equal to output dimension\n",
        "\n",
        "        self.m = nn.ModuleList([self.net() for _ in range(self.num_flows)])\n",
        "\n",
        "        self.s = nn.Parameter(torch.rand(input_dim), requires_grad=True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x[0].to(torch.float32)\n",
        "        x = x.view(len(x), -1,) / 255\n",
        "        return self.f(x)\n",
        "\n",
        "    def coupling_layer(self, x, m, flow, forward=True):\n",
        "        x = x.clone()\n",
        "\n",
        "        x_a = x[:, ::2] if flow%2==0 else x[:, 1::2]\n",
        "        x_b = x[:, 1::2] if flow%2==0 else x[:, ::2]\n",
        "\n",
        "        if forward:\n",
        "            y_b = (x_b - m(x_a))\n",
        "        else:\n",
        "            y_b = (x_b + m(x_a))\n",
        "\n",
        "        #z = torch.concat((x_a, y_b), axis=1) if flow%2==0 else torch.concat((y_b, x_a), axis=1)\n",
        "        z = torch.empty(x.shape)\n",
        "        z[:, ::2] = x_a if flow%2==0 else y_b\n",
        "        z[:, 1::2] = y_b if flow%2==0 else x_a\n",
        "        return z\n",
        "\n",
        "\n",
        "    def f(self, x):\n",
        "        z = x\n",
        "\n",
        "        for flow, model in enumerate(self.m, start=0):\n",
        "            z = self.coupling_layer(z, model, flow, forward=True)\n",
        "\n",
        "        z = z * torch.exp(self.s)\n",
        "        log_det_j = self.s.reshape(-1,1)\n",
        "\n",
        "        return z, log_det_j\n",
        "\n",
        "    def f_inv(self, z):\n",
        "        x = z / torch.exp(self.s)\n",
        "\n",
        "        for flow, model in reversed(list(enumerate(self.m, start=0))):\n",
        "            x = self.coupling_layer(x, model, flow,forward=False)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def criterion(self, z, prior, log_det_j, reduction = \"sum\"):\n",
        "\n",
        "        if reduction == \"sum\":\n",
        "            loss = - (prior.log_prob(z) + log_det_j).sum()\n",
        "        else:\n",
        "\n",
        "            loss = - (prior.log_prob(z) + log_det_j).mean()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "dNv7fminO_d7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image = torchvision.datasets.MNIST(root='dataset', train=True, download=True, transform=transforms.ToTensor())\n",
        "test_image = torchvision.datasets.MNIST(root='dataset', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "\n",
        "train_data = Data(train_image)\n",
        "test_data = Data(test_image)"
      ],
      "metadata": {
        "id": "61Bk8bccO_gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179717ee-e898-405d-8c85-ba46c5de219c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 245162935.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 112684366.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 92123446.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2514257.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_train, category_train = train_data[0]\n",
        "image_test, category_test = test_data[0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(image_train.reshape((28,28)), cmap='gray')\n",
        "plt.title(f'train\\ntarget : {category_train}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(image_test.reshape((28,28)), cmap='gray')\n",
        "plt.title(f'test\\ntarget : {category_test}')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "mn2HDNucO_i_",
        "outputId": "c1242cc2-9856-4722-eca0-e58811dee890"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dim = 28*28\n",
        "prior = torch.distributions.multivariate_normal.MultivariateNormal(loc=torch.zeros((data_dim)),\n",
        "                                                    scale_tril=torch.diag(torch.ones((data_dim))))\n",
        "\n",
        "model = NICE(input_dim=data_dim, hidden_layer=128, num_flows=10)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=10000, shuffle=True)\n"
      ],
      "metadata": {
        "id": "rQs7Q0x8O_lW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "COST = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = []\n",
        "\n",
        "    for x in train_loader:\n",
        "\n",
        "        z, log_det_j = model.forward(x)\n",
        "        loss = model.criterion(z, prior, log_det_j, reduction=\"avg\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "    COST.append(np.mean(total_loss))\n",
        "\n",
        "    if epoch==0:\n",
        "        print(\"Epoch : \", epoch+1, \"  -----------> Loss : \", np.mean(total_loss))\n",
        "    elif (epoch+1)%1 == 0:\n",
        "        print(\"Epoch : \", epoch+1, \"  -----------> Loss : \", np.mean(total_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wwMpBqaBO_np",
        "outputId": "f6109bfc-4e31-472e-ee59-8b046cadead0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  1   -----------> Loss :  822.294667561849\n",
            "Epoch :  2   -----------> Loss :  791.9211832682291\n",
            "Epoch :  3   -----------> Loss :  782.7786560058594\n",
            "Epoch :  4   -----------> Loss :  773.4451802571615\n",
            "Epoch :  5   -----------> Loss :  765.7327779134115\n",
            "Epoch :  6   -----------> Loss :  759.652353922526\n",
            "Epoch :  7   -----------> Loss :  754.3229675292969\n",
            "Epoch :  8   -----------> Loss :  749.9232991536459\n",
            "Epoch :  9   -----------> Loss :  746.6592203776041\n",
            "Epoch :  10   -----------> Loss :  744.020751953125\n",
            "Epoch :  11   -----------> Loss :  741.8758138020834\n",
            "Epoch :  12   -----------> Loss :  740.774169921875\n",
            "Epoch :  13   -----------> Loss :  739.0570983886719\n",
            "Epoch :  14   -----------> Loss :  737.6383361816406\n",
            "Epoch :  15   -----------> Loss :  736.8695983886719\n",
            "Epoch :  16   -----------> Loss :  736.0606282552084\n",
            "Epoch :  17   -----------> Loss :  734.9295450846354\n",
            "Epoch :  18   -----------> Loss :  734.045908610026\n",
            "Epoch :  19   -----------> Loss :  733.271250406901\n",
            "Epoch :  20   -----------> Loss :  732.6073710123698\n",
            "Epoch :  21   -----------> Loss :  732.0028483072916\n",
            "Epoch :  22   -----------> Loss :  731.4546610514323\n",
            "Epoch :  23   -----------> Loss :  730.9673970540365\n",
            "Epoch :  24   -----------> Loss :  730.520741780599\n",
            "Epoch :  25   -----------> Loss :  730.1447957356771\n",
            "Epoch :  26   -----------> Loss :  729.749521891276\n",
            "Epoch :  27   -----------> Loss :  729.376210530599\n",
            "Epoch :  28   -----------> Loss :  729.0401713053385\n",
            "Epoch :  29   -----------> Loss :  728.7201741536459\n",
            "Epoch :  30   -----------> Loss :  728.4943542480469\n",
            "Epoch :  31   -----------> Loss :  728.2462768554688\n",
            "Epoch :  32   -----------> Loss :  727.9315897623698\n",
            "Epoch :  33   -----------> Loss :  727.6474100748698\n",
            "Epoch :  34   -----------> Loss :  727.3928426106771\n",
            "Epoch :  35   -----------> Loss :  727.2268880208334\n",
            "Epoch :  36   -----------> Loss :  727.0898234049479\n",
            "Epoch :  37   -----------> Loss :  726.8247477213541\n",
            "Epoch :  38   -----------> Loss :  726.5975240071615\n",
            "Epoch :  39   -----------> Loss :  726.3883870442709\n",
            "Epoch :  40   -----------> Loss :  726.2252909342448\n",
            "Epoch :  41   -----------> Loss :  726.1820882161459\n",
            "Epoch :  42   -----------> Loss :  726.1028238932291\n",
            "Epoch :  43   -----------> Loss :  725.9335327148438\n",
            "Epoch :  44   -----------> Loss :  725.683349609375\n",
            "Epoch :  45   -----------> Loss :  725.496327718099\n",
            "Epoch :  46   -----------> Loss :  725.335439046224\n",
            "Epoch :  47   -----------> Loss :  725.2049763997396\n",
            "Epoch :  48   -----------> Loss :  725.1287943522135\n",
            "Epoch :  49   -----------> Loss :  725.018564860026\n",
            "Epoch :  50   -----------> Loss :  724.9214274088541\n",
            "Epoch :  51   -----------> Loss :  724.7804667154948\n",
            "Epoch :  52   -----------> Loss :  724.676503499349\n",
            "Epoch :  53   -----------> Loss :  724.6082661946615\n",
            "Epoch :  54   -----------> Loss :  724.556874593099\n",
            "Epoch :  55   -----------> Loss :  724.4312947591146\n",
            "Epoch :  56   -----------> Loss :  724.3322550455729\n",
            "Epoch :  57   -----------> Loss :  724.3012288411459\n",
            "Epoch :  58   -----------> Loss :  724.2085673014323\n",
            "Epoch :  59   -----------> Loss :  724.1043599446615\n",
            "Epoch :  60   -----------> Loss :  724.0171305338541\n",
            "Epoch :  61   -----------> Loss :  724.0079956054688\n",
            "Epoch :  62   -----------> Loss :  723.9447530110677\n",
            "Epoch :  63   -----------> Loss :  723.8338928222656\n",
            "Epoch :  64   -----------> Loss :  723.7610066731771\n",
            "Epoch :  65   -----------> Loss :  723.8338928222656\n",
            "Epoch :  66   -----------> Loss :  723.7529703776041\n",
            "Epoch :  67   -----------> Loss :  723.6312459309896\n",
            "Epoch :  68   -----------> Loss :  723.5503234863281\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8a9d55c12c70>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"avg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-59d2f6894b0b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcoupling_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-59d2f6894b0b>\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoupling_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-59d2f6894b0b>\u001b[0m in \u001b[0;36mcoupling_layer\u001b[0;34m(self, x, m, flow, forward)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_a\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_b\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(COST)"
      ],
      "metadata": {
        "id": "3lgGpF_wybkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = prior.sample((50,))\n",
        "test"
      ],
      "metadata": {
        "id": "qJy70H-_O_pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sonuc = model.f_inv(test)\n"
      ],
      "metadata": {
        "id": "rjNtmsr9O_sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = prior.sample((10,))\n",
        "sonuc = model.f_inv(test)\n",
        "\n",
        "fig, axs = plt.subplots(1, 10, sharex=True, sharey=True, figsize=(16, 8))\n",
        "\n",
        "for i in range(0,10):\n",
        "\n",
        "    axs[i].imshow(sonuc[i].detach().numpy().reshape((28,28)), cmap='gray')\n",
        "    #axs[i].axis('off')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EJXVv9wyPMXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtRXTPLzotDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}